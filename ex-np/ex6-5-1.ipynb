{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = [('Omnicom', 'IN', 'New York'),\n",
    "         ('DDB Needham', 'IN', 'New York'),\n",
    "         ('Kaplan Thaler Group', 'IN', 'New York'),\n",
    "         ('BBDO South', 'IN', 'Atlanta'),\n",
    "         ('Georgia-Pacific', 'IN', 'Atlanta')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBDO South', 'Georgia-Pacific']\n"
     ]
    }
   ],
   "source": [
    "query = [e1 for (e1, rel, e2) in locs if e2=='Atlanta']\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking은 문장에서 짧은 구(phrase)를 추출하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), \n",
    "            (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  \n",
    "            (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "#sentence = [(\"another\", \"DT\"), (\"sharp\", \"JJ\"), (\"drive\", \"NN\"),\n",
    "#            (\"trade\", \"NN\"), (\"figures\", \"NNS\"),\n",
    "#            (\"any\", \"DT\"), (\"new\", \"JJ\"), (\"policy\", \"NN\"), (\"measures\", \"NNS\"),\n",
    "#            (\"earlier\", \"JJR\"), (\"stages\", \"NNS\"),\n",
    "#            (\"Panamanian\", \"JJ\"), (\"dictator\", \"NN\"), (\"Manuel\", \"NNP\"), (\"Noriega\", \"NNP\")]\n",
    "#sentence = [(\"his\", \"PRP\"), (\"Mansion\", \"NNP\"), (\"House\", \"NNP\"), (\"Speech\", \"NN\"),\n",
    "#            (\"the\", \"DT\"), (\"price\", \"NN\"), (\"cutting\", \"VBG\"),\n",
    "#            (\"3\", \"CD\"), (\"%\", \"NN\"), (\"to\", \"TO\"), (\"4\", \"CD\"), (\"%\", \"NN\"), \n",
    "#            (\"more\", \"JJR\"), (\"than\", \"IN\"), (\"10\", \"CD\"), (\"%\", \"NN\"),  \n",
    "#            (\"the\", \"DT\"), (\"fastest\", \"JJS\"), (\"developing\", \"VBG\"), (\"trends\", \"NNS\"),\n",
    "#            (\"'s\", \"POS\"), (\"skill\", \"NN\")]\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\" \n",
    "#grammar = \"NP:{<DT>?<JJ.*>*<NN.*>+}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar) \n",
    "result = cp.parse(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  his/PRP\n",
      "  (NP Mansion/NNP House/NNP Speech/NN)\n",
      "  (NP the/DT price/NN)\n",
      "  cutting/VBG\n",
      "  3/CD\n",
      "  (NP %/NN)\n",
      "  to/TO\n",
      "  4/CD\n",
      "  (NP %/NN)\n",
      "  more/JJR\n",
      "  than/IN\n",
      "  10/CD\n",
      "  (NP %/NN)\n",
      "  the/DT\n",
      "  fastest/JJS\n",
      "  developing/VBG\n",
      "  (NP trends/NNS)\n",
      "  's/POS\n",
      "  (NP skill/NN))\n"
     ]
    }
   ],
   "source": [
    "print(result) \n",
    "result.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), \n",
    "                 (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Rapunzel/NNP)\n",
      "  let/VBD\n",
      "  down/RP\n",
      "  (NP her/PP$ long/JJ golden/JJ hair/NN))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PP Over/IN)\n",
      "  (NP a/DT cup/NN)\n",
      "  (PP of/IN)\n",
      "  (NP coffee/NN)\n",
      "  ,/,\n",
      "  (NP Mr./NNP Stone/NNP)\n",
      "  (VP told/VBD)\n",
      "  (NP his/PRP$ story/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "print(conll2000.chunked_sents('train.txt')[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Over/IN\n",
      "  (NP a/DT cup/NN)\n",
      "  of/IN\n",
      "  (NP coffee/NN)\n",
      "  ,/,\n",
      "  (NP Mr./NNP Stone/NNP)\n",
      "  told/VBD\n",
      "  (NP his/PRP$ story/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(conll2000.chunked_sents('train.txt', chunk_types=['NP'])[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Lalbagh/NNP)\n",
      "  (PERSON Botanical/NNP Gardens/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  well/RB\n",
      "  known/VBN\n",
      "  botanical/JJ\n",
      "  garden/NN\n",
      "  in/IN\n",
      "  (GPE Bengaluru/NNP)\n",
      "  ,/,\n",
      "  (GPE India/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Lalbagh Botanical Gardens is a well known botanical garden in Bengaluru, India.\"\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    chunks = nltk.ne_chunk(tags)\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
